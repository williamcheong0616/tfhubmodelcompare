{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkgTD7NoBrMNfYu+UaRA/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamcheong0616/tfhubmodelcompare/blob/master/WilliamTest1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE8I6zjGPsJY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_image_cache = {}\n",
        "\n",
        "def preprocess_image(image):\n",
        "  image = np.array(image)\n",
        "  # reshape into shape [batch_size, height, width, num_channels]\n",
        "  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)\n",
        "  return image\n",
        "\n",
        "def load_image_from_url(img_url):\n",
        "  \"\"\"Returns an image with shape [1, height, width, num_channels].\"\"\"\n",
        "  user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n",
        "  response = requests.get(img_url, headers=user_agent)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  image = preprocess_image(image)\n",
        "  return image\n",
        "\n",
        "def load_image(image_url, image_size=256, dynamic_size=False, max_dynamic_size=512):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Cache image file locally.\n",
        "  if image_url in original_image_cache:\n",
        "    img = original_image_cache[image_url]\n",
        "  elif image_url.startswith('https://'):\n",
        "    img = load_image_from_url(image_url)\n",
        "  else:\n",
        "    fd = tf.io.gfile.GFile(image_url, 'rb')\n",
        "    img = preprocess_image(Image.open(fd))\n",
        "  original_image_cache[image_url] = img\n",
        "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "  img_raw = img\n",
        "  if tf.reduce_max(img) > 1.0:\n",
        "    img = img / 255.\n",
        "  if len(img.shape) == 3:\n",
        "    img = tf.stack([img, img, img], axis=-1)\n",
        "  if not dynamic_size:\n",
        "    img = tf.image.resize_with_pad(img, image_size, image_size)\n",
        "  elif img.shape[1] > max_dynamic_size or img.shape[2] > max_dynamic_size:\n",
        "    img = tf.image.resize_with_pad(img, max_dynamic_size, max_dynamic_size)\n",
        "  return img, img_raw\n",
        "\n",
        "def show_image(image, title=''):\n",
        "  image_size = image.shape[1]\n",
        "  w = (image_size * 6) // 320\n",
        "  plt.figure(figsize=(w, w))\n",
        "  plt.imshow(image[0], aspect='equal')\n",
        "  plt.axis('off')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "labels_file = \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\"\n",
        "\n",
        "#download labels and creates a maps\n",
        "downloaded_file = tf.keras.utils.get_file(\"labels.txt\", origin=labels_file)\n",
        "\n",
        "classes = []\n",
        "\n",
        "with open(downloaded_file) as f:\n",
        "  labels = f.readlines()\n",
        "  classes = [l.strip() for l in labels]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JqKvhYG4P6p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [\n",
        "    \"googlenet[incepv1](2014)\",\n",
        "    \"inception_v3(2015)\",\n",
        "    \"inception_resnet_v2(2016)\",\n",
        "    \"mobilenet(2017)\",\n",
        "    \"mobilenet-v2(2018)\",\n",
        "    \"mobilenet-v3(2019)\",\n",
        "    \"bit-s-resnet101x3-1k(2020)\",\n",
        "    \"bit-m-resnet101x3-1k(2020)\",\n",
        "    \"efficientnet-v2-l-1k(2021)\",\n",
        "    \"mlp-mixer-l-1k(2021)\"\n",
        "]\n",
        "#ay caramba, el problema testo here\n",
        "#model_list = [\"mlp-mixer-l-1k(2021)\"]\n",
        "#images_list = [\"tiger\"]\n",
        "images_list = [\n",
        "    \"tiger\",\n",
        "    \"bus\",\n",
        "    \"car\",\n",
        "    \"cat\",\n",
        "    \"dog\",\n",
        "    \"apple\",\n",
        "    \"banana\",\n",
        "    \"turtle\",\n",
        "    \"flamingo\",\n",
        "    \"piano\",\n",
        "    \"honeycomb\",\n",
        "    \"teapot\",\n",
        "    \"beaver\",\n",
        "    \"cannon\",\n",
        "    \"forklift\",\n",
        "    \"pillow\",\n",
        "    \"radio\",\n",
        "    \"snorkel\",\n",
        "    \"stove\",\n",
        "    \"tractor\",\n",
        "    \"yurt\",\n",
        "    \"pretzel\"\n",
        "]\n",
        "modelcount = []\n",
        "highpasses = []\n",
        "passes = []\n",
        "lowpasses = []\n",
        "rawscore = []\n",
        "totalmodelcount = 0\n",
        "for _ in range(len(model_list)):\n",
        "    modelcount.append(0)\n",
        "    rawscore.append(0)\n",
        "    highpasses.append(0)\n",
        "    passes.append(0)\n",
        "    lowpasses.append(0)\n",
        "for j in model_list:\n",
        "    toggle = 0\n",
        "    model_name = j\n",
        "    model_handle_map = {\n",
        "      \"googlenet[incepv1](2014)\": \"https://tfhub.dev/google/imagenet/inception_v1/classification/5\",\n",
        "      \"inception_v3(2015)\": \"https://tfhub.dev/google/imagenet/inception_v3/classification/4\",\n",
        "      \"inception_resnet_v2(2016)\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/4\",\n",
        "      \"mobilenet(2017)\": \"https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/classification/5\",\n",
        "      \"mobilenet-v2(2018)\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\",\n",
        "      \"mobilenet-v3(2019)\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\",\n",
        "      \"bit-s-resnet101x3-1k(2020)\": \"https://tfhub.dev/google/bit/s-r101x3/ilsvrc2012_classification/1\",\n",
        "      \"bit-m-resnet101x3-1k(2020)\": \"https://tfhub.dev/google/bit/m-r101x3/ilsvrc2012_classification/1\",\n",
        "      \"efficientnet-v2-l-1k(2021)\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/classification/2\",\n",
        "      \"mlp-mixer-l-1k(2021)\": \"https://tfhub.dev/sayakpaul/mixer_l16_i1k_classification/1\"\n",
        "    }\n",
        "\n",
        "    model_image_size_map = {\n",
        "      \"googlenet[incepv1](2014)\": 224,\n",
        "      \"inception_v3(2015)\": 299,\n",
        "      \"inception_resnet_v2(2016)\": 299,\n",
        "      \"mobilenet(2017)\": 224,\n",
        "      \"mobilenet-v2(2018)\": 224,\n",
        "      \"mobilenet-v3(2019)\": 224,\n",
        "      \"bit-s-resnet101x3-1k(2020)\": 224,\n",
        "      \"bit-m-resnet101x3-1k(2020)\": 224,\n",
        "      \"efficientnet-v2-l-1k(2021)\": 480,\n",
        "      \"mlp-mixer-l-1k(2021)\": 224\n",
        "    }\n",
        "\n",
        "    model_handle = model_handle_map[model_name]\n",
        "\n",
        "    #print(f\"Selected model: {model_name} : {model_handle}\")\n",
        "    for l in images_list:\n",
        "\n",
        "        image_name = l\n",
        "        image_size = 224\n",
        "        dynamic_size = False\n",
        "        max_dynamic_size = 512\n",
        "        images_for_test_map = {\n",
        "            \"tiger\": \"https://upload.wikimedia.org/wikipedia/commons/b/b0/Bengal_tiger_%28Panthera_tigris_tigris%29_female_3_crop.jpg\",\n",
        "            \"bus\": \"https://upload.wikimedia.org/wikipedia/commons/6/63/LT_471_%28LTZ_1471%29_Arriva_London_New_Routemaster_%2819522859218%29.jpg\",\n",
        "            \"car\": \"https://upload.wikimedia.org/wikipedia/commons/4/49/2013-2016_Toyota_Corolla_%28ZRE172R%29_SX_sedan_%282018-09-17%29_01.jpg\",\n",
        "            \"cat\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/CatVibrissaeFullFace.JPG/1200px-CatVibrissaeFullFace.JPG\",\n",
        "            \"dog\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Bakarwal.jpg/1200px-Bakarwal.jpg\",\n",
        "            \"apple\": \"https://upload.wikimedia.org/wikipedia/commons/1/15/Red_Apple.jpg\",\n",
        "            \"banana\": \"https://upload.wikimedia.org/wikipedia/commons/1/1c/Bananas_white_background.jpg\",\n",
        "            \"turtle\": \"https://upload.wikimedia.org/wikipedia/commons/8/80/Turtle_golfina_escobilla_oaxaca_mexico_claudio_giovenzana_2010.jpg\",\n",
        "            \"flamingo\": \"https://upload.wikimedia.org/wikipedia/commons/b/b8/James_Flamingos_MC.jpg\",\n",
        "            \"piano\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Steinway_%26_Sons_concert_grand_piano%2C_model_D-274%2C_manufactured_at_Steinway%27s_factory_in_Hamburg%2C_Germany.png/1200px-Steinway_%26_Sons_concert_grand_piano%2C_model_D-274%2C_manufactured_at_Steinway%27s_factory_in_Hamburg%2C_Germany.png\",\n",
        "            \"honeycomb\": \"https://upload.wikimedia.org/wikipedia/commons/f/f7/Honey_comb.jpg\",\n",
        "            \"teapot\": \"https://upload.wikimedia.org/wikipedia/commons/4/44/Black_tea_pot_cropped.jpg\",\n",
        "            \"beaver\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Beaver_pho34.jpg/640px-Beaver_pho34.jpg\",\n",
        "            \"cannon\": \"https://upload.wikimedia.org/wikipedia/commons/4/4f/Canon_obusier_de_campagne_de_12_modele_1853.jpg\",\n",
        "            \"forklift\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/1956_Toyota_Model_LA_Forklift_01.jpg/1200px-1956_Toyota_Model_LA_Forklift_01.jpg\",\n",
        "            \"pillow\": \"https://upload.wikimedia.org/wikipedia/commons/a/ad/Pillows_on_a_hotel_bed.jpg\",\n",
        "            \"radio\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Radio.jpg/717px-Radio.jpg\",\n",
        "            \"snorkel\": \"https://upload.wikimedia.org/wikipedia/commons/8/8c/Snorkel.jpg\",\n",
        "            \"stove\": \"https://upload.wikimedia.org/wikipedia/commons/9/99/Gas_stove.jpg\",\n",
        "            \"tractor\": \"https://upload.wikimedia.org/wikipedia/commons/3/3f/Nuffield_tractor%2C_Cophill_Farm_vintage_rally_2012.jpg\",\n",
        "            \"yurt\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Kyrgyzsk%C3%A1_jurta%2C_Song-k%C3%B6l.jpg/640px-Kyrgyzsk%C3%A1_jurta%2C_Song-k%C3%B6l.jpg\",\n",
        "            \"pretzel\": \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRmwqOgdCHrdf02pO5wI2TeFKkU2kwTgNkuAg&usqp=CAU\",\n",
        "        }\n",
        "\n",
        "        img_url = images_for_test_map[image_name]\n",
        "        image, original_image = load_image(img_url, image_size, dynamic_size, max_dynamic_size)\n",
        "        #show_image(image, 'Scaled image')\n",
        "\n",
        "        if model_name in model_image_size_map:\n",
        "            image_size = model_image_size_map[model_name]\n",
        "            image_size = tf.cast(image_size, tf.float32)\n",
        "            dynamic_size = False\n",
        "            #print(f\"Images will be converted to {image_size}x{image_size}\")\n",
        "        else:\n",
        "            dynamic_size = True\n",
        "            #print(f\"Images will be capped to a max size of {max_dynamic_size}x{max_dynamic_size}\")\n",
        "\n",
        "\n",
        "\n",
        "        #class\n",
        "        classifier = hub.load(model_handle)\n",
        "\n",
        "        input_shape = image.shape\n",
        "        warmup_input = tf.random.uniform(input_shape, 0, 1.0)\n",
        "        try:\n",
        "            if(toggle == 0):\n",
        "                %time warmup_logits = classifier(warmup_input).numpy()\n",
        "                toggle = 1\n",
        "            else:\n",
        "                warmup_logits = classifier(warmup_input).numpy()\n",
        "\n",
        "\n",
        "            # Run model on image\n",
        "            #%time probabilities = tf.nn.softmax(classifier(image)).numpy()\n",
        "            probabilities = tf.nn.softmax(classifier(image)).numpy()\n",
        "            top_1 = tf.argsort(probabilities, axis=-1, direction=\"DESCENDING\")[0][:1].numpy()\n",
        "            np_classes = np.array(classes)\n",
        "\n",
        "            # Some models include an additional 'background' class in the predictions, so\n",
        "            # we must account for this when reading the class labels.\n",
        "            includes_background_class = probabilities.shape[1] == 1001\n",
        "\n",
        "            for i, item in enumerate(top_1):\n",
        "                class_index = item if includes_background_class else item + 1\n",
        "                #line = f'({i+1}) {class_index:4} - {classes[class_index]}: {probabilities[0][top_1][i]}'\n",
        "                #print(line)\n",
        "                try:\n",
        "                    line = classes[class_index]\n",
        "                    if(image_name in line):\n",
        "                        if(probabilities[0][top_1][i] < 0.5):\n",
        "                            passed = \"Low Pass\"\n",
        "                            lowpasses[totalmodelcount] += 1\n",
        "                        elif(probabilities[0][top_1][i] < 0.75):\n",
        "                            passed = \"Pass\"\n",
        "                            passes[totalmodelcount] += 1\n",
        "                        else:\n",
        "                            passed = \"High Pass\"\n",
        "                            highpasses[totalmodelcount] += 1\n",
        "                        rawscore[totalmodelcount] += probabilities[0][top_1][i]\n",
        "                    else:\n",
        "                        passed = \"Fail\"\n",
        "                    print(line + \": \" + f'{probabilities[0][top_1][i]*100:3.2f}' + \", \" + passed + \" - \" + model_name)\n",
        "                #show_image(image, '')\n",
        "                except IndexError:\n",
        "                    passed = \"Fail\"\n",
        "                    print(\"none\" + \": \" + f'{0:3.2f}' + \", \" + passed + \" - \" + model_name)\n",
        "        except Exception as e:\n",
        "            print(model_name + \" failed to run.\")\n",
        "            print(e)\n",
        "    totalmodelcount+=1\n",
        "    print()\n",
        "print(\"Ready.\")"
      ],
      "metadata": {
        "id": "41OrwQBfP9GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for k in range(totalmodelcount):\n",
        "    print(\"75+%: \" + f'{highpasses[k]}' + \", 50%-75%: \" + f'{passes[k]}' + \", <50%: \" + f'{lowpasses[k]}' +\n",
        "          \" Average acc: \" + f'{rawscore[k]/len(images_list)*100:3.2f}' +\n",
        "          \"% - \" + model_list[k])\n",
        "\n"
      ],
      "metadata": {
        "id": "U_h9ERhVQAim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}